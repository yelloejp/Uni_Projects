{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification with MNIST dataset\n",
    "MNIST dataset contains 65,000 handwritten digit images which size is 28 by 28. CNNs model is used for image classifcation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library used\n",
    "For the task, it mainly uses tensorflow and matplotlib for visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1) Read dataset \n",
    "MNIST contains 65,000 images. 55,000 for training set and the rest for testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of each image is 28 by 28 and each image has a label in the range of 0 to 9. When visualizing the image randomly, it looks like following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2153f792f98>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = 5000\n",
    "plt.imshow(mnist.train.images[images].reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2) Build CNN structure \n",
    "To implement CNNs in Tensorflow, there is two different variables concepts called Placeholder and Variable. Placeholder is similar to a variable which carrying data. Variable is a parameter of the algorithm. \n",
    "\n",
    "It defines independent and dependent variables called X and Y. X is image and Y is label. The size of image is 28 by 28. It can process the certain number of images and the input size is 784(28x28). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1]) # gray scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN model here builds 3 layers, first hidden layer, second hidden layer and fully connected layer. In first layer, it uses 32 filters which size is 3x3x1 with max pooling. After passing the first layer, the size of image becomes 14x14x32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32]))\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In second layer, it uses 64 filters which size is 3x3x32 with max pooling. After passing the first layer, the size of image becomes 7x7x64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second layer\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64])) \n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fully connected layer, it should reshape the layer to flat. Then it gets a layer which size is 3136."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected layer\n",
    "L2 = tf.reshape(L2, [-1, 7*7*64])\n",
    "W3 = tf.get_variable(\"W3\", shape=[7*7*64, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "B = tf.Variable(tf.random_normal([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step3) Set cost function and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.matmul(L2, W3) + B\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "optimizer= tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step4) Train the model\n",
    "For each epoch, it processes 100 images. After 10 iterations, its accuracy on testing data is 0.9751. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 170.04250562083917\n",
      "1 4.591602135752333\n",
      "2 3.3116890602570517\n",
      "3 3.2099733780589332\n",
      "4 3.072328393791394\n",
      "5 3.3961040907262894\n",
      "6 3.1987190199177316\n",
      "7 3.470390222891367\n",
      "8 3.268065386656622\n",
      "9 3.231512241617735\n",
      "Accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0\n",
    "        num_iterations = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "        for iteration in range(num_iterations):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            cost_val, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += cost_val / num_epochs\n",
    "        \n",
    "        print(epoch, avg_cost)\n",
    "        \n",
    "    print(\"Accuracy:\", sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
