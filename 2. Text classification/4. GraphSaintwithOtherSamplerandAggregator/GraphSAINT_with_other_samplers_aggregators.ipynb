{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6. GraphSAINT_with_other_samplers.ipynb","provenance":[{"file_id":"1fCfv13K0wngPx9pTSJtq66vcv9sFJnyH","timestamp":1604858726026},{"file_id":"14OvFnAXggxB8vM4e8vSURUp1TaKnovzX","timestamp":1603452334087}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2Dpfoq_iTNd-"},"source":["# This notebook uses different random samplers called Spiky Ball and Common Neighbor Aware Random Walk sampler and different aggregators"]},{"cell_type":"markdown","metadata":{"id":"ccuMkoY59-wK"},"source":["Spiky Ball Sampler(in 2020), Common Neighbor Aware Random Walk Sampler(in 2019)"]},{"cell_type":"markdown","metadata":{"id":"cAHwl5vmTKN7"},"source":["## Install and import required packages"]},{"cell_type":"code","metadata":{"id":"VQyfP47BPCZc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605640500973,"user_tz":-60,"elapsed":15588,"user":{"displayName":"EUNJU PARK","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj68gAA8PrQqWDvDZkxrYCsV0m9hKw3JMbhPmPHVQ=s64","userId":"05570688855093486946"}},"outputId":"5fd60497-d39c-4d64-9275-e687b74ce942"},"source":["# Install required packages of PyTorch Geometric\n","!pip install -q torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n","!pip install -q torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n","!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wxQhEqotMap1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605640506664,"user_tz":-60,"elapsed":5685,"user":{"displayName":"EUNJU PARK","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj68gAA8PrQqWDvDZkxrYCsV0m9hKw3JMbhPmPHVQ=s64","userId":"05570688855093486946"}},"outputId":"0586f3fe-b8aa-4d63-fdbf-9b9657a48df4"},"source":["# this part is so time consuming. be patient\n","!pip install littleballoffur\n","!pip install littleballoffur --upgrade"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: littleballoffur in /usr/local/lib/python3.6/dist-packages (2.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (1.15.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (2.5)\n","Requirement already satisfied: python-louvain in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (0.14)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (1.18.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (1.4.1)\n","Requirement already satisfied: networkit in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (7.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (4.41.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (1.1.4)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->littleballoffur) (4.4.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->littleballoffur) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->littleballoffur) (2.8.1)\n","Requirement already up-to-date: littleballoffur in /usr/local/lib/python3.6/dist-packages (2.1.2)\n","Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (1.1.4)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (1.18.5)\n","Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (2.5)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (4.41.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (1.15.0)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (1.4.1)\n","Requirement already satisfied, skipping upgrade: python-louvain in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (0.14)\n","Requirement already satisfied, skipping upgrade: networkit in /usr/local/lib/python3.6/dist-packages (from littleballoffur) (7.1)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->littleballoffur) (2.8.1)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->littleballoffur) (2018.9)\n","Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->littleballoffur) (4.4.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NvZFcesjPFDv"},"source":["import torch\n","from torch.nn import Linear\n","import torch.nn.functional as F\n","from torch_geometric.data import Data, DataLoader\n","from torch_geometric.nn import GCNConv\n","import numpy as np\n","from torch_geometric.utils.convert import to_networkx\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","from torch_geometric.datasets import Yelp, Flickr, Amazon"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HBgBDEVoMF64"},"source":["import networkx as nx\n","import matplotlib.pyplot as plt\n","from littleballoffur import SpikyBallSampler, CommonNeighborAwareRandomWalkSampler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pyD4GgV7ToPL"},"source":["## Load graph datasets "]},{"cell_type":"code","metadata":{"id":"v5IoJFCRZ9jw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605645686113,"user_tz":-60,"elapsed":622,"user":{"displayName":"EUNJU PARK","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj68gAA8PrQqWDvDZkxrYCsV0m9hKw3JMbhPmPHVQ=s64","userId":"05570688855093486946"}},"outputId":"f8e7377e-0b07-44fc-aa50-a78b1e7bfd5f"},"source":["dataset = Flickr(root='data/Flickr')\n","data = dataset[0] \n","print(data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Data(edge_index=[2, 899756], test_mask=[89250], train_mask=[89250], val_mask=[89250], x=[89250, 500], y=[89250])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5uRdjh2z-cNI"},"source":["## Define Samplers\n"]},{"cell_type":"code","metadata":{"id":"ZbJfuwjjIXHV"},"source":["def Geometric_SpikyBallSampler(data, G_data, batch_size):\n","  N = data.num_nodes\n","  Spiky = SpikyBallSampler()\n","  sample_list = []  \n","  for i in range(int(N/batch_size)):\n","    num_node = len(Spiky.sample(G_data).nodes)\n","    sampled_edges = [node for node in Spiky.sample(G_data).edges]\n","\n","    edge1 = [edge[0] for edge in sampled_edges]\n","    edge2 = [edge[1] for edge in sampled_edges]\n","    \n","    sampled_nodes = list(set(edge1+edge2))\n","    node_index = np.arange(0, len(sampled_nodes))\n","    node_dict = dict(zip(sampled_nodes, node_index))\n","    edge1 = [node_dict.get(e) for e in edge1]\n","    edge2 = [node_dict.get(e) for e in edge2]\n","\n","    sample_edge = torch.stack([torch.tensor(edge1), torch.tensor(edge2)])\n","\n","    sample_y = data.y[sampled_nodes]\n","    sample_x = data.x[sampled_nodes]\n","\n","    sample_train_mask = data.train_mask[sampled_nodes]\n","    sample_test_mask = data.test_mask[sampled_nodes]\n","    sample_val_mask = data.val_mask[sampled_nodes]\n","\n","    sample_data = Data(x=sample_x, edge_index=sample_edge, y=sample_y)\n","    \n","    sample_data.train_mask = sample_train_mask\n","    sample_data.test_mask = sample_test_mask\n","    sample_data.val_mask = sample_val_mask\n","\n","    sample_list.append(sample_data)  \n","\n","  return sample_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIIyN0Cf7g37"},"source":["def Geometric_CommonNeighborAwareRandomWalkSampler(data, G_data, n_nodes, batch_size):\n","  N = data.num_nodes\n","  CNARS = CommonNeighborAwareRandomWalkSampler(n_nodes)\n","  sample_list = []  \n","  for i in range(int(N/batch_size)):\n","    num_node = len(CNARS.sample(G_data).nodes)\n","    sampled_edges = [node for node in CNARS.sample(G_data).edges]\n","\n","    edge1 = [edge[0] for edge in sampled_edges]\n","    edge2 = [edge[1] for edge in sampled_edges]\n","    \n","    sampled_nodes = list(set(edge1+edge2))\n","    node_index = np.arange(0, len(sampled_nodes))\n","    node_dict = dict(zip(sampled_nodes, node_index))\n","    edge1 = [node_dict.get(e) for e in edge1]\n","    edge2 = [node_dict.get(e) for e in edge2]\n","\n","    sample_edge = torch.stack([torch.tensor(edge1), torch.tensor(edge2)])\n","\n","    sample_y = data.y[sampled_nodes]\n","    sample_x = data.x[sampled_nodes]\n","\n","    sample_train_mask = data.train_mask[sampled_nodes]\n","    sample_test_mask = data.test_mask[sampled_nodes]\n","    sample_val_mask = data.val_mask[sampled_nodes]\n","\n","    sample_data = Data(x=sample_x, edge_index=sample_edge, y=sample_y)\n","    \n","    sample_data.train_mask = sample_train_mask\n","    sample_data.test_mask = sample_test_mask\n","    sample_data.val_mask = sample_val_mask\n","\n","    sample_list.append(sample_data)  \n","\n","  return sample_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TP-kf5AEVLof"},"source":["G_data = to_networkx(data, to_undirected=True)\n","\n","sample_loader = Geometric_SpikyBallSampler(data, G_data, 6000) \n","sample_loader = Geometric_CommonNeighborAwareRandomWalkSampler(data, G_data, 5000, 6000) \n","\n","for data in sample_loader:\n","  sample = data\n","  break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f3XIj869ImYc"},"source":["## Define model and train"]},{"cell_type":"code","metadata":{"id":"puVoTGMwIl6Y"},"source":["##########################################################################\n","# Our graph doen't have information of num_classes unfortunately. \n","# so manually.... (R8:8, oshumed:23, mr:2, yelp:23)\n","##########################################################################\n","class Net(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super(Net, self).__init__()\n","        in_channels = 500  #dataset.num_features \n","        out_channels = 7 #dataset.num_classes \n","        self.conv1 = GCNConv(in_channels, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n","        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n","        self.lin = torch.nn.Linear(3 * hidden_channels, out_channels)\n","\n","    def set_aggr(self, aggr):\n","        self.conv1.aggr = aggr\n","        self.conv2.aggr = aggr\n","        self.conv3.aggr = aggr\n","\n","    def forward(self, x0, edge_index, edge_weight=None):\n","        x1 = F.relu(self.conv1(x0, edge_index, edge_weight))\n","        x1 = F.dropout(x1, p=0.2, training=self.training)\n","        x2 = F.relu(self.conv2(x1, edge_index, edge_weight))\n","        x2 = F.dropout(x2, p=0.2, training=self.training)\n","        x3 = F.relu(self.conv3(x2, edge_index, edge_weight))\n","        x3 = F.dropout(x3, p=0.2, training=self.training)\n","        x = torch.cat([x1, x2, x3], dim=-1)\n","        x = self.lin(x)\n","        \n","        return x.log_softmax(dim=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nHD95guW4Stw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605645899635,"user_tz":-60,"elapsed":471,"user":{"displayName":"EUNJU PARK","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj68gAA8PrQqWDvDZkxrYCsV0m9hKw3JMbhPmPHVQ=s64","userId":"05570688855093486946"}},"outputId":"af85a29f-61f7-4832-b4ea-b5dcafd2df21"},"source":["###########################################################################\n","# Our graph doen't have information of num_classes unfortunately. \n","# so manually.... (R8:8, oshumed:23, mr:2, yelp:23)\n","##########################################################################\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(hidden_channels=256).to(device)\n","criterion = torch.nn.CrossEntropyLoss()  \n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Net(\n","  (conv1): GCNConv(500, 256)\n","  (conv2): GCNConv(256, 256)\n","  (conv3): GCNConv(256, 256)\n","  (lin): Linear(in_features=768, out_features=7, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B2gxeGJ7HnSU"},"source":["# train function\n","def train():\n","    model.train()\n","    model.set_aggr('add') # This aggregator \"add\" can be change to \"max\", \"mean\" or commented out this line as \"none\"\n","    total_loss = total_examples = 0\n","    for data in sample_loader:\n","        data = data.to(device)\n","        optimizer.zero_grad()        \n","        out = model(data.x, data.edge_index)\n","        loss = F.nll_loss(out, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item() * data.num_nodes\n","        total_examples += data.num_nodes\n","    return total_loss / total_examples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9zCOyZ0JNd72"},"source":["# test function\n","@torch.no_grad()\n","def test():\n","    model.eval()\n","    model.set_aggr('add') # This aggregator \"add\" can be change to \"max\", \"mean\" or commented out this line as \"none\"\n","\n","    out = model(data.x.to(device), data.edge_index.to(device))\n","    pred = out.argmax(dim=-1)\n","    correct = pred.eq(data.y.to(device)) \n","\n","    accs = []\n","    accs = []\n","    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n","        accs.append(correct[mask].sum().item() / mask.sum().item())\n","    return accs "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-4npNB-bJUc8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605646268854,"user_tz":-60,"elapsed":364315,"user":{"displayName":"EUNJU PARK","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj68gAA8PrQqWDvDZkxrYCsV0m9hKw3JMbhPmPHVQ=s64","userId":"05570688855093486946"}},"outputId":"5fc78508-f1fa-4fc7-e545-8f86f7219056"},"source":["# print results\n","for epoch in range(1, 51):\n","    loss = train()\n","    accs = test()\n","    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {accs[0]:.4f}, Val: {accs[1]:.4f}, Test: {accs[2]:.4f}') "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 01, Loss: 1.7607, Train: 0.4042, Val: 0.4323, Test: 0.4185\n","Epoch: 02, Loss: 1.7259, Train: 0.4178, Val: 0.4467, Test: 0.4177\n","Epoch: 03, Loss: 1.6684, Train: 0.4174, Val: 0.4361, Test: 0.4161\n","Epoch: 04, Loss: 1.6219, Train: 0.4191, Val: 0.4422, Test: 0.4177\n","Epoch: 05, Loss: 1.5954, Train: 0.4331, Val: 0.4528, Test: 0.4407\n","Epoch: 06, Loss: 1.5790, Train: 0.4430, Val: 0.4543, Test: 0.4446\n","Epoch: 07, Loss: 1.5638, Train: 0.4476, Val: 0.4589, Test: 0.4494\n","Epoch: 08, Loss: 1.5500, Train: 0.4517, Val: 0.4574, Test: 0.4509\n","Epoch: 09, Loss: 1.5396, Train: 0.4554, Val: 0.4627, Test: 0.4557\n","Epoch: 10, Loss: 1.5277, Train: 0.4608, Val: 0.4627, Test: 0.4589\n","Epoch: 11, Loss: 1.5158, Train: 0.4653, Val: 0.4650, Test: 0.4604\n","Epoch: 12, Loss: 1.5061, Train: 0.4682, Val: 0.4703, Test: 0.4628\n","Epoch: 13, Loss: 1.4957, Train: 0.4785, Val: 0.4772, Test: 0.4644\n","Epoch: 14, Loss: 1.4833, Train: 0.4860, Val: 0.4848, Test: 0.4731\n","Epoch: 15, Loss: 1.4724, Train: 0.4851, Val: 0.4909, Test: 0.4818\n","Epoch: 16, Loss: 1.4632, Train: 0.4901, Val: 0.4932, Test: 0.4834\n","Epoch: 17, Loss: 1.4522, Train: 0.4934, Val: 0.5023, Test: 0.4889\n","Epoch: 18, Loss: 1.4414, Train: 0.4975, Val: 0.5053, Test: 0.4968\n","Epoch: 19, Loss: 1.4323, Train: 0.4971, Val: 0.5114, Test: 0.5032\n","Epoch: 20, Loss: 1.4220, Train: 0.5012, Val: 0.5114, Test: 0.5032\n","Epoch: 21, Loss: 1.4111, Train: 0.5066, Val: 0.5190, Test: 0.5095\n","Epoch: 22, Loss: 1.4015, Train: 0.5116, Val: 0.5236, Test: 0.5111\n","Epoch: 23, Loss: 1.3911, Train: 0.5128, Val: 0.5320, Test: 0.5166\n","Epoch: 24, Loss: 1.3816, Train: 0.5215, Val: 0.5373, Test: 0.5229\n","Epoch: 25, Loss: 1.3699, Train: 0.5244, Val: 0.5388, Test: 0.5198\n","Epoch: 26, Loss: 1.3581, Train: 0.5310, Val: 0.5403, Test: 0.5277\n","Epoch: 27, Loss: 1.3509, Train: 0.5351, Val: 0.5434, Test: 0.5253\n","Epoch: 28, Loss: 1.3435, Train: 0.5326, Val: 0.5449, Test: 0.5309\n","Epoch: 29, Loss: 1.3350, Train: 0.5388, Val: 0.5502, Test: 0.5324\n","Epoch: 30, Loss: 1.3273, Train: 0.5367, Val: 0.5586, Test: 0.5419\n","Epoch: 31, Loss: 1.3170, Train: 0.5434, Val: 0.5586, Test: 0.5467\n","Epoch: 32, Loss: 1.3090, Train: 0.5475, Val: 0.5578, Test: 0.5451\n","Epoch: 33, Loss: 1.3009, Train: 0.5512, Val: 0.5662, Test: 0.5475\n","Epoch: 34, Loss: 1.2977, Train: 0.5528, Val: 0.5601, Test: 0.5538\n","Epoch: 35, Loss: 1.2883, Train: 0.5541, Val: 0.5731, Test: 0.5609\n","Epoch: 36, Loss: 1.2822, Train: 0.5586, Val: 0.5807, Test: 0.5593\n","Epoch: 37, Loss: 1.2752, Train: 0.5623, Val: 0.5784, Test: 0.5633\n","Epoch: 38, Loss: 1.2688, Train: 0.5723, Val: 0.5906, Test: 0.5578\n","Epoch: 39, Loss: 1.2668, Train: 0.5723, Val: 0.5974, Test: 0.5609\n","Epoch: 40, Loss: 1.2606, Train: 0.5756, Val: 0.5944, Test: 0.5625\n","Epoch: 41, Loss: 1.2565, Train: 0.5747, Val: 0.5921, Test: 0.5665\n","Epoch: 42, Loss: 1.2489, Train: 0.5718, Val: 0.5868, Test: 0.5688\n","Epoch: 43, Loss: 1.2372, Train: 0.5756, Val: 0.5921, Test: 0.5767\n","Epoch: 44, Loss: 1.2322, Train: 0.5756, Val: 0.5906, Test: 0.5775\n","Epoch: 45, Loss: 1.2272, Train: 0.5801, Val: 0.5936, Test: 0.5823\n","Epoch: 46, Loss: 1.2209, Train: 0.5809, Val: 0.5928, Test: 0.5815\n","Epoch: 47, Loss: 1.2188, Train: 0.5834, Val: 0.6027, Test: 0.5752\n","Epoch: 48, Loss: 1.2153, Train: 0.5888, Val: 0.6012, Test: 0.5815\n","Epoch: 49, Loss: 1.2103, Train: 0.5871, Val: 0.5959, Test: 0.5847\n","Epoch: 50, Loss: 1.2036, Train: 0.5896, Val: 0.5967, Test: 0.5767\n"],"name":"stdout"}]}]}